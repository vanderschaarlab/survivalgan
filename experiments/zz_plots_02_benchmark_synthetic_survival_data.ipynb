{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733120b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from synthcity.benchmark import Benchmarks\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.utils.serialization import load_from_file, save_to_file\n",
    "\n",
    "from datasets import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b0b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"output\")\n",
    "prefix = \"privacy.identifiability_score\"\n",
    "\n",
    "metrics = [\n",
    "    \"sanity.data_mismatch.score\",\n",
    "    \"sanity.common_rows_proportion.score\",\n",
    "    \"sanity.nearest_syn_neighbor_distance.mean\",\n",
    "    \"sanity.close_values_probability.score\",\n",
    "    \"sanity.distant_values_probability.score\",\n",
    "    \"stats.jensenshannon_dist.marginal\",\n",
    "    \"stats.chi_squared_test.marginal\",\n",
    "    \"stats.feature_corr.joint\",\n",
    "    \"stats.inv_kl_divergence.marginal\",\n",
    "    \"stats.ks_test.marginal\",\n",
    "    \"stats.max_mean_discrepancy.joint\",\n",
    "    \"stats.wasserstein_dist.joint\",\n",
    "    \"stats.prdc.precision\",\n",
    "    \"stats.prdc.recall\",\n",
    "    \"stats.prdc.density\",\n",
    "    \"stats.prdc.coverage\",\n",
    "    \"stats.alpha_precision.delta_precision_alpha\",\n",
    "    \"stats.alpha_precision.delta_coverage_beta\",\n",
    "    \"stats.alpha_precision.authenticity\",\n",
    "    \"performance.linear_model.gt\",\n",
    "    \"performance.linear_model.syn_id\",\n",
    "    \"performance.linear_model.syn_ood\",\n",
    "    \"performance.mlp.gt\",\n",
    "    \"performance.mlp.syn_id\",\n",
    "    \"performance.mlp.syn_ood\",\n",
    "    \"performance.xgb.gt\",\n",
    "    \"performance.xgb.syn_id\",\n",
    "    \"performance.xgb.syn_ood\",\n",
    "    \"detection.detection_xgb.mean\",\n",
    "    \"detection.detection_mlp.mean\",\n",
    "    \"detection.detection_gmm.mean\",\n",
    "    \"privacy.delta-presence.score\",\n",
    "    \"privacy.k-anonymization.gt\",\n",
    "    \"privacy.k-anonymization.syn\",\n",
    "    \"privacy.k-map.score\",\n",
    "    \"privacy.distinct l-diversity.gt\",\n",
    "    \"privacy.distinct l-diversity.syn\",\n",
    "    \"privacy.identifiability_score.score\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_metric(\n",
    "    dataset: str,\n",
    "    metric: str,\n",
    "    models=[\n",
    "        \"baseline_adsgan\",\n",
    "        \"baseline_ctgan\",\n",
    "        \"baseline_tvae\",\n",
    "        \"baseline_privbayes\",\n",
    "        \"baseline_nflow\",\n",
    "        \"survival_survival_gan\",\n",
    "    ],\n",
    "):\n",
    "    results = []\n",
    "    for name in models:\n",
    "        bkp = out_dir / f\"{prefix}.{dataset}_{name}.bkp\"\n",
    "        df, duration_col, event_col, time_horizons = get_dataset(dataset)\n",
    "\n",
    "        try:\n",
    "            score = load_from_file(bkp)\n",
    "        except BaseException as e:\n",
    "            print(\"failed to load file\", e)\n",
    "            continue\n",
    "\n",
    "        for model in score:\n",
    "            method_score = score[model]\n",
    "            local_df = method_score.loc[metric].copy()\n",
    "            local_df[\"model\"] = model\n",
    "            results.append(local_df.to_frame().T)\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc182be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b0ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(action=\"once\")\n",
    "\n",
    "# sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f7740a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "fontsize = 10\n",
    "text_kwargs = dict(fontsize=fontsize)\n",
    "\n",
    "\n",
    "def generate_plot_for_ax(ax, title, data):\n",
    "    datasets = data[\"dataset\"].unique()\n",
    "    datasets_cnt = len(datasets)\n",
    "\n",
    "    barWidth = 1\n",
    "\n",
    "    max_val = 0\n",
    "    idx = 0\n",
    "\n",
    "    models = [\n",
    "        \"adsgan\",\n",
    "        \"ctgan\",\n",
    "        \"tvae\",\n",
    "        \"privbayes\",\n",
    "        \"nflow\",\n",
    "        \"survival_gan\",\n",
    "    ]\n",
    "    cases = [\n",
    "        (\"#30a2da\", \"adsgan\"),\n",
    "        (\"#ff9cde\", \"ctgan\"),\n",
    "        (\"#e5ae38\", \"tvae\"),\n",
    "        (\"#6d904f\", \"privbayes\"),\n",
    "        (\"#8b8b8b\", \"nflow\"),\n",
    "        (\"#D23e4e\", \"survival_gan\"),\n",
    "    ]\n",
    "    models_cnt = len(models)\n",
    "\n",
    "    maxval = 0\n",
    "\n",
    "    for color, model in cases:\n",
    "        base_mod_mean = data[data[\"model\"] == model][\"mean\"]\n",
    "        base_mod_std = data[data[\"model\"] == model][\"std\"]\n",
    "        if len(base_mod_mean) == 0:\n",
    "            print(\"invalid model\", model)\n",
    "            continue\n",
    "\n",
    "        edgecolor = \"k\"\n",
    "\n",
    "        idxs = [\n",
    "            (idx + ((models_cnt + 1) * r)) * barWidth for r in range(len(base_mod_mean))\n",
    "        ]\n",
    "        ax.bar(\n",
    "            idxs,\n",
    "            base_mod_mean.values,\n",
    "            yerr=base_mod_std.values,\n",
    "            width=barWidth,\n",
    "            label=model,\n",
    "            edgecolor=edgecolor,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "        maxval = max(maxval, max((base_mod_mean + base_mod_std).values))\n",
    "        idx += 1\n",
    "\n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.2),\n",
    "        ncol=models_cnt,\n",
    "        prop={\"size\": fontsize},\n",
    "    )\n",
    "\n",
    "    pretty_data = [map_dataset(d) for d in datasets]\n",
    "\n",
    "    ax.set_xticks(\n",
    "        [(models_cnt + 1) * r + int(models_cnt / 2) for r in range(datasets_cnt)],\n",
    "        pretty_data,\n",
    "        rotation=0,\n",
    "        fontsize=fontsize,\n",
    "    )\n",
    "\n",
    "    # ax.set_yticks([0.2 * v for v in range(int(10 * maxval) + 2)], fontsize=100)\n",
    "    ax.set_ylabel(title, fontsize=fontsize)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=fontsize)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def generate_plot(title, data):\n",
    "    # ['Solarize_Light2', '_classic_test_patch', '_mpl-gallery', '_mpl-gallery-nogrid', 'bmh', 'classic', 'dark_background', 'fast',\n",
    "    #'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "    plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "    offset = len(data)\n",
    "    fig, axs = plt.subplots(1, figsize=(3 * len(data[\"dataset\"].unique()), 3))\n",
    "\n",
    "    generate_plot_for_ax(axs, title, data)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.35)\n",
    "    plt.savefig(f\"diagrams/metrics_{title}.png\")\n",
    "    plt.savefig(f\"diagrams/metrics_{title}.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_performance_table(title, df, datasets):\n",
    "    str_repr = [\n",
    "        f\"{round(m, 4)} +/- {round(s, 4)}\"\n",
    "        for m, s in zip(df[\"mean\"].values, df[\"std\"].values)\n",
    "    ]\n",
    "    df[\"str\"] = str_repr\n",
    "    df = df.drop(columns=[\"mean\", \"std\"])\n",
    "\n",
    "    piv = df.pivot_table(\n",
    "        values=\"str\", index=df[\"model\"], columns=\"dataset\", aggfunc=\"first\"\n",
    "    )\n",
    "    display(piv[datasets])\n",
    "\n",
    "\n",
    "def extract_performance(\n",
    "    datasets: list, title: str, metrics: list, direction: str = \"maximize\"\n",
    "):\n",
    "    headers = [\"model\", \"mean\", \"std\", \"dataset\"]\n",
    "    res_df = pd.DataFrame([], columns=headers)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        results = []\n",
    "\n",
    "        for metric in metrics:\n",
    "            try:\n",
    "                local_metrics = get_metric(dataset, metric)\n",
    "\n",
    "                results.append(local_metrics.reset_index(drop=True))\n",
    "            except BaseException as e:\n",
    "                raise\n",
    "                print(\"get metric failed\", e)\n",
    "                continue\n",
    "\n",
    "        if len(results) == 0:\n",
    "            continue\n",
    "\n",
    "        for idx, row in results[0].iterrows():\n",
    "            local_results = pd.concat(\n",
    "                [v.iloc[idx].to_frame().T for v in results], ignore_index=True\n",
    "            )\n",
    "\n",
    "            if direction == \"maximize\":\n",
    "                best_result = local_results[\n",
    "                    local_results[\"mean\"] == local_results[\"mean\"].max()\n",
    "                ]\n",
    "            elif direction == \"minimize\":\n",
    "                best_result = local_results[\n",
    "                    local_results[\"mean\"] == local_results[\"mean\"].min()\n",
    "                ]\n",
    "            else:\n",
    "                raise RuntimeError(f\"invalid direction {direction}\")\n",
    "\n",
    "            local_df = pd.DataFrame(\n",
    "                [\n",
    "                    [\n",
    "                        best_result[\"model\"].values[0],\n",
    "                        best_result[\"mean\"].values[0],\n",
    "                        best_result[\"stddev\"].values[0],\n",
    "                        dataset,\n",
    "                    ]\n",
    "                ],\n",
    "                columns=headers,\n",
    "            )\n",
    "            res_df = pd.concat([res_df, local_df], ignore_index=True)\n",
    "\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def plot_performance(\n",
    "    datasets: list, title: str, metrics: list, direction: str = \"maximize\"\n",
    "):\n",
    "    res_df = extract_performance(datasets, title, metrics, direction)\n",
    "\n",
    "    print(\"Scenario\", title)\n",
    "    print_performance_table(title, res_df, datasets)\n",
    "    generate_plot(title, res_df)\n",
    "\n",
    "    print(\"=\" * 100)\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def plot_performance_with_baseline(\n",
    "    datasets: list,\n",
    "    title: str,\n",
    "    metrics: list,\n",
    "    baseline_metrics: list,\n",
    "    direction: str = \"maximize\",\n",
    "):\n",
    "    res_df = extract_performance(datasets, title, metrics, direction)\n",
    "    res_base_df = extract_performance(datasets, title, baseline_metrics, direction)\n",
    "\n",
    "    print(\"Scenario\", title, res_base_df)\n",
    "    print_performance_table(title, res_df, datasets)\n",
    "    generate_plot(title, res_df)\n",
    "\n",
    "    print(\"=\" * 100)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549c43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b87d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea62dc5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3d23f67",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d76f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8812e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0293ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a5363d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to load file [Errno 2] No such file or directory: 'output/privacy.identifiability_score.aids_baseline_adsgan.bkp'\n",
      "failed to load file [Errno 2] No such file or directory: 'output/privacy.identifiability_score.aids_baseline_ctgan.bkp'\n",
      "failed to load file [Errno 2] No such file or directory: 'output/privacy.identifiability_score.aids_baseline_tvae.bkp'\n",
      "failed to load file [Errno 2] No such file or directory: 'output/privacy.identifiability_score.aids_baseline_privbayes.bkp'\n",
      "failed to load file [Errno 2] No such file or directory: 'output/privacy.identifiability_score.aids_baseline_nflow.bkp'\n",
      "failed to load file [Errno 2] No such file or directory: 'output/privacy.identifiability_score.aids_survival_survival_gan.bkp'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m title, direction, metrics \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m      4\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdentifiability\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprivacy.identifiability_score.score\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m      5\u001b[0m ]:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mplot_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 175\u001b[0m, in \u001b[0;36mplot_performance\u001b[0;34m(datasets, title, metrics, direction)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_performance\u001b[39m(\n\u001b[1;32m    173\u001b[0m     datasets: \u001b[38;5;28mlist\u001b[39m, title: \u001b[38;5;28mstr\u001b[39m, metrics: \u001b[38;5;28mlist\u001b[39m, direction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m ):\n\u001b[0;32m--> 175\u001b[0m     res_df \u001b[38;5;241m=\u001b[39m \u001b[43mextract_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScenario\u001b[39m\u001b[38;5;124m\"\u001b[39m, title)\n\u001b[1;32m    178\u001b[0m     print_performance_table(title, res_df, datasets)\n",
      "Cell \u001b[0;32mIn[4], line 129\u001b[0m, in \u001b[0;36mextract_performance\u001b[0;34m(datasets, title, metrics, direction)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         local_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mget_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(local_metrics\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[2], line 75\u001b[0m, in \u001b[0;36mget_metric\u001b[0;34m(dataset, metric, models)\u001b[0m\n\u001b[1;32m     72\u001b[0m         local_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     73\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(local_df\u001b[38;5;241m.\u001b[39mto_frame()\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/code/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/code/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/code/anaconda3/envs/py38/lib/python3.8/site-packages/pandas/core/reshape/concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "datasets = [\"aids\"]\n",
    "\n",
    "for title, direction, metrics in [\n",
    "    (\"Identifiability\", \"minimize\", [\"privacy.identifiability_score.score\"]),\n",
    "]:\n",
    "\n",
    "    plot_performance(datasets, direction=direction, title=title, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd2f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a5333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
