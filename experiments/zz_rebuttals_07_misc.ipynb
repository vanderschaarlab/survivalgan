{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e40306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aids [ 61.5 122.  182.5 243.  303.5]\n",
      "cutract [1051. 2082. 3113. 4144. 5175.]\n",
      "maggic [1404.66666667 2809.33333333 4214.         5618.66666667 7023.33333333]\n",
      "seer [ 775. 1550. 2325. 3100. 3875.]\n",
      "metabric [ 56.25555555 112.4111111  168.56666665 224.7222222  280.87777775]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "for dataset in [\"aids\", \"cutract\", \"maggic\", \"seer\", \"metabric\"]:\n",
    "    df, duration_col, event_col, time_horizons = get_dataset(dataset)\n",
    "\n",
    "    print(dataset, np.linspace(df[duration_col].min(), df[duration_col].max(), 7)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "233e50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import synthcity.logger as log\n",
    "from adjutorium.plugins.prediction.risk_estimation import RiskEstimation\n",
    "from adjutorium.utils.metrics import generate_score, print_score\n",
    "from adjutorium.utils.tester import evaluate_survival_estimator\n",
    "from synthcity.benchmark import Benchmarks\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import SurvivalAnalysisDataLoader\n",
    "from synthcity.utils.serialization import (dataframe_hash, load_from_file,\n",
    "                                           save_to_file)\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "log.remove()\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "workspace_dir = Path(\"workspace\")\n",
    "\n",
    "plugins = [\n",
    "    \"survival_gan\",\n",
    "    \"ctgan\",\n",
    "    \"tvae\",\n",
    "]\n",
    "\n",
    "\n",
    "def evaluate_dataset(dataset: str):\n",
    "    df, duration_col, event_col, time_horizons = get_dataset(dataset)\n",
    "    df_hash = dataframe_hash(df)\n",
    "\n",
    "    X = df.drop(columns=[duration_col, event_col])\n",
    "    T = df[duration_col]\n",
    "    E = df[event_col]\n",
    "\n",
    "    for plugin in plugins:\n",
    "        print(\" >>> \", plugin)\n",
    "\n",
    "        for horizon in time_horizons:\n",
    "            cindex = []\n",
    "            brier = []\n",
    "\n",
    "            for seed in range(5):\n",
    "                model_bkp = workspace_dir / f\"{df_hash}_{plugin}_{seed}.bkp\"\n",
    "\n",
    "                syn_df = load_from_file(model_bkp)\n",
    "                try:\n",
    "                    syn_df = syn_df.dataframe()\n",
    "                except BaseException:\n",
    "                    pass\n",
    "\n",
    "                Xsyn = syn_df.drop(columns=[duration_col, event_col])\n",
    "                Tsyn = syn_df[duration_col]\n",
    "                Esyn = syn_df[event_col]\n",
    "\n",
    "                model = RiskEstimation().get(\"survival_xgboost\")\n",
    "                try:\n",
    "                    model.fit(Xsyn, Tsyn, Esyn)\n",
    "\n",
    "                    score = evaluate_survival_estimator(\n",
    "                        [model] * 3,\n",
    "                        X,\n",
    "                        T,\n",
    "                        E,\n",
    "                        time_horizons=[horizon],\n",
    "                        pretrained=True,\n",
    "                        metrics=[\"c_index\", \"brier_score\"],\n",
    "                    )\n",
    "                    # print(\"          \", seed, horizon, score[\"str\"])\n",
    "\n",
    "                    cindex.append(score[\"clf\"][\"c_index\"][0])\n",
    "                    brier.append(score[\"clf\"][\"brier_score\"][0])\n",
    "\n",
    "                except BaseException:\n",
    "                    continue\n",
    "            print(\n",
    "                f\"          horizon = {horizon}. ciondex = {print_score(generate_score(cindex))} brier = {print_score(generate_score(brier))}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3050611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>>  survival_gan\n",
      "          horizon = 91.75. ciondex = 0.748 +/- 0.032 brier = 0.042 +/- 0.001\n",
      "          horizon = 182.5. ciondex = 0.719 +/- 0.034 brier = 0.071 +/- 0.004\n",
      "          horizon = 273.25. ciondex = 0.705 +/- 0.034 brier = 0.086 +/- 0.004\n",
      " >>>  ctgan\n",
      "          horizon = 91.75. ciondex = 0.506 +/- 0.106 brier = 0.043 +/- 0.001\n",
      "          horizon = 182.5. ciondex = 0.502 +/- 0.101 brier = 0.074 +/- 0.004\n",
      "          horizon = 273.25. ciondex = 0.502 +/- 0.102 brier = 0.101 +/- 0.009\n",
      " >>>  tvae\n",
      "None\n",
      "          horizon = 91.75. ciondex = 0.611 +/- 0.091 brier = 0.043 +/- 0.0\n",
      "None\n",
      "          horizon = 182.5. ciondex = 0.59 +/- 0.073 brier = 0.072 +/- 0.001\n",
      "None\n",
      "          horizon = 273.25. ciondex = 0.578 +/- 0.063 brier = 0.093 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(\"aids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6584dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>>  survival_gan\n",
      "          horizon = 1566.5. ciondex = 0.783 +/- 0.012 brier = 0.044 +/- 0.004\n",
      "          horizon = 3113.0. ciondex = 0.772 +/- 0.016 brier = 0.154 +/- 0.041\n",
      "          horizon = 4659.5. ciondex = 0.74 +/- 0.017 brier = 0.208 +/- 0.052\n",
      " >>>  ctgan\n",
      "          horizon = 1566.5. ciondex = 0.822 +/- 0.01 brier = 0.064 +/- 0.007\n",
      "          horizon = 3113.0. ciondex = 0.809 +/- 0.008 brier = 0.216 +/- 0.038\n",
      "          horizon = 4659.5. ciondex = 0.782 +/- 0.007 brier = 0.327 +/- 0.048\n",
      " >>>  tvae\n",
      "          horizon = 1566.5. ciondex = 0.719 +/- 0.024 brier = 0.062 +/- 0.018\n",
      "          horizon = 3113.0. ciondex = 0.706 +/- 0.024 brier = 0.111 +/- 0.02\n",
      "          horizon = 4659.5. ciondex = 0.68 +/- 0.02 brier = 0.163 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(\"cutract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bda1eb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>>  survival_gan\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'workspace/4879234145147014154_survival_gan_3.bkp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaggic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mevaluate_dataset\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     41\u001b[0m     model_bkp \u001b[38;5;241m=\u001b[39m workspace_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.bkp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 43\u001b[0m     syn_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_bkp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m         syn_df \u001b[38;5;241m=\u001b[39m syn_df\u001b[38;5;241m.\u001b[39mdataframe()\n",
      "File \u001b[0;32m/code/code/vds/synthcity/src/synthcity/utils/serialization.py:24\u001b[0m, in \u001b[0;36mload_from_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_file\u001b[39m(path: Union[\u001b[38;5;28mstr\u001b[39m, Path]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cloudpickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'workspace/4879234145147014154_survival_gan_3.bkp'"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(\"maggic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb14acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_dataset(\"seer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd441f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f5ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141bde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import synthcity.logger as log\n",
    "from adjutorium.plugins.prediction.risk_estimation import RiskEstimation\n",
    "from adjutorium.utils.tester import evaluate_survival_estimator\n",
    "from synthcity.benchmark import Benchmarks\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import SurvivalAnalysisDataLoader\n",
    "from synthcity.utils.serialization import (dataframe_hash, load_from_file,\n",
    "                                           save_to_file)\n",
    "\n",
    "from datasets import get_dataset\n",
    "\n",
    "log.remove()\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "workspace_dir = Path(\"workspace_rebuttal\")\n",
    "\n",
    "\n",
    "def evaluate_dataset(dataset: str, plugin: tuple, repeats: int = 2):\n",
    "    df, duration_col, event_col, time_horizons = get_dataset(dataset)\n",
    "    df_hash = dataframe_hash(df)\n",
    "\n",
    "    X = df.drop(columns=[duration_col, event_col])\n",
    "    T = df[duration_col]\n",
    "    E = df[event_col]\n",
    "\n",
    "    for horizon in time_horizons:\n",
    "        model_bkp = workspace_dir / f\"{df_hash}_{plugin}_{plugin}__0.bkp\"\n",
    "\n",
    "        syn_df = load_from_file(model_bkp)\n",
    "        try:\n",
    "            syn_df = syn_df.dataframe()\n",
    "        except BaseException:\n",
    "            pass\n",
    "\n",
    "        Xsyn = syn_df.drop(columns=[duration_col, event_col])\n",
    "        Tsyn = syn_df[duration_col]\n",
    "        Esyn = syn_df[event_col]\n",
    "\n",
    "        model = RiskEstimation().get(\"survival_xgboost\")\n",
    "        model.fit(Xsyn, Tsyn, Esyn)\n",
    "\n",
    "        score = evaluate_survival_estimator(\n",
    "            [model] * 3,\n",
    "            X,\n",
    "            T,\n",
    "            E,\n",
    "            time_horizons=[horizon],\n",
    "            pretrained=True,\n",
    "            metrics=[\"c_index\", \"brier_score\"],\n",
    "        )\n",
    "        print(horizon, score[\"str\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "205e8661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.333333325 {'c_index': '0.737 +/- 0.038', 'brier_score': '0.074 +/- 0.013'}\n",
      "168.56666665 {'c_index': '0.738 +/- 0.024', 'brier_score': '0.224 +/- 0.025'}\n",
      "252.79999997500002 {'c_index': '0.665 +/- 0.011', 'brier_score': '0.245 +/- 0.018'}\n"
     ]
    }
   ],
   "source": [
    "evaluate_dataset(\"metabric\", \"survival_gan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d6a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
